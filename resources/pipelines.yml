# =============================================================================
# Lakeflow Declarative Pipelines Configuration
# =============================================================================
# Modern SQL-based pipeline architecture using Lakeflow Spark Declarative Pipelines
# All transformations (Bronze -> Silver -> Gold) are done in pure SQL
#
# Architecture:
# S3 -> Lambda Sync -> UC Volume -> Streaming Tables (Bronze) -> 
#   Materialized Views (Silver) -> Materialized Views (Gold)
#
# COST OPTIMIZED:
# - SINGLE NODE (num_workers: 0) for development
# - m5d.large (2 vCPU, 8GB RAM)
# - 100% SPOT instances
# - NO PHOTON (unless needed for performance)
# =============================================================================

resources:
  pipelines:
    # ==========================================================================
    # Main Lakehouse Pipeline - All Layers (Bronze -> Silver -> Gold)
    # ==========================================================================
    iot_lakehouse_pipeline:
      name: "iot-lakehouse-${bundle.target}"
      
      # Development mode for rapid iteration (set to false in prod)
      development: false
      
      # Triggered mode for cost savings (not continuous)
      # Set to true for near-real-time streaming in production
      continuous: false
      
      # Pipeline channel
      channel: "CURRENT"
      
      # Unity Catalog configuration
      catalog: ${var.catalog}
      target: ${var.schema_prefix}
      
      # =======================================================================
      # Pipeline Source Code - SQL Declarative Pipelines
      # =======================================================================
      libraries:
        # Bronze Layer - Streaming Tables (Ingestion)
        - file:
            path: ../pipelines/bronze/ingest_iot_events.sql
        - file:
            path: ../pipelines/bronze/ingest_cdc_customers.sql
        - file:
            path: ../pipelines/bronze/ingest_cdc_products.sql
        - file:
            path: ../pipelines/bronze/ingest_cdc_orders.sql
        - file:
            path: ../pipelines/bronze/ingest_cdc_devices.sql
        - file:
            path: ../pipelines/bronze/ingest_cdc_locations.sql
        - file:
            path: ../pipelines/bronze/ingest_cdc_alerts.sql
        - file:
            path: ../pipelines/bronze/ingest_cdc_alert_thresholds.sql
        
        # Silver Layer - Materialized Views (Staging/Transformations)
        - file:
            path: ../pipelines/silver/stg_iot_events.sql
        - file:
            path: ../pipelines/silver/stg_customers.sql
        - file:
            path: ../pipelines/silver/stg_products.sql
        - file:
            path: ../pipelines/silver/stg_orders.sql
        - file:
            path: ../pipelines/silver/stg_devices.sql
        - file:
            path: ../pipelines/silver/stg_locations.sql
        - file:
            path: ../pipelines/silver/stg_alerts.sql
        - file:
            path: ../pipelines/silver/stg_alert_thresholds.sql
        
        # Gold Layer - Dimensions
        - file:
            path: ../pipelines/gold/dimensions/dim_customers.sql
        - file:
            path: ../pipelines/gold/dimensions/dim_devices.sql
        - file:
            path: ../pipelines/gold/dimensions/dim_locations.sql
        - file:
            path: ../pipelines/gold/dimensions/dim_date.sql
        
        # Gold Layer - Facts
        - file:
            path: ../pipelines/gold/facts/fct_iot_events.sql
        - file:
            path: ../pipelines/gold/facts/fct_alerts.sql
        - file:
            path: ../pipelines/gold/facts/fct_orders.sql
        
        # Gold Layer - Analytics Aggregations
        - file:
            path: ../pipelines/gold/analytics/agg_daily_device_metrics.sql
        - file:
            path: ../pipelines/gold/analytics/agg_customer_summary.sql
        - file:
            path: ../pipelines/gold/analytics/agg_hourly_device_metrics.sql
      
      # =======================================================================
      # Cluster Configuration - Cost Optimized
      # =======================================================================
      clusters:
        - label: "default"
          # SINGLE NODE for development
          num_workers: 0
          node_type_id: "m5d.large"
          
          # 100% SPOT instances for cost savings
          aws_attributes:
            availability: SPOT
            zone_id: auto
            spot_bid_price_percent: 100
            first_on_demand: 0
          
          spark_conf:
            "spark.databricks.cluster.profile": "singleNode"
            "spark.master": "local[*]"
            "spark.databricks.delta.optimizeWrite.enabled": "true"
            "spark.databricks.delta.autoCompact.enabled": "true"
            "spark.sql.shuffle.partitions": "4"
          
          custom_tags:
            ResourceClass: "SingleNode"
            Project: "iot-lakehouse"
            Environment: "${bundle.target}"
            Architecture: "LakeflowDeclarativePipelines"
      
      # Photon - Enable for production workloads
      photon: false
      
      # Pipeline configuration
      configuration:
        # Schema evolution
        "spark.databricks.delta.schema.autoMerge.enabled": "true"
        # Catalog parameter for SQL pipelines
        "catalog": "${var.catalog}"
