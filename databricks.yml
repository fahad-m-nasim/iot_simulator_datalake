# Databricks Asset Bundle Configuration
# IoT Streaming Pipeline - Bronze/Silver/Gold Architecture
#
# Deploy with: databricks bundle deploy -t dev
# Validate with: databricks bundle validate
#
# IMPORTANT: Update the 'host' value in your ~/.databrickscfg or use 
# environment variables DATABRICKS_HOST and DATABRICKS_TOKEN

bundle:
  name: iot-streaming-pipeline

# Include resource definitions from separate files
include:
  - resources/*.yml

# Variables for parameterization across environments
variables:
  # S3 bucket for raw data landing (external landing zone)
  s3_bucket:
    description: "S3 bucket containing raw IoT and CDC data"
    default: "dev-iot-streaming-gvits-usw2-471112583087"
  
  # Catalog for Unity Catalog
  catalog:
    description: "Unity Catalog name"
    default: "iot_streaming"
  
  # Schema prefix for environments
  schema_prefix:
    description: "Schema prefix for environment isolation"
    default: "dev"
  
  # Compute node type - using smallest for cost savings
  node_type:
    description: "EC2 instance type for clusters"
    default: "m5d.large"  # 2 vCPU, 8GB RAM - smallest viable, COST OPTIMIZED
  
  # Auto-terminate timeout
  autotermination_minutes:
    description: "Cluster auto-termination timeout"
    default: 15
  
  # AWS region
  aws_region:
    description: "AWS region for resources"
    default: "us-west-2"

# Workspace configuration
workspace:
  # Root path for bundle deployment
  root_path: /Workspace/Users/${workspace.current_user.userName}/.bundle/${bundle.name}/${bundle.target}
  
  # File path for artifacts
  file_path: /Workspace/Users/${workspace.current_user.userName}/.bundle/${bundle.name}/${bundle.target}/files
  
  # Artifact path for libraries
  artifact_path: /Workspace/Users/${workspace.current_user.userName}/.bundle/${bundle.name}/${bundle.target}/artifacts

# Target environments
targets:
  # Development environment - lowest cost
  dev:
    # NOTE: Using 'presets' instead of 'mode: development' to have more control
    # mode: development forces DLT pipeline development=true (keeps cluster running)
    # We want auto-termination, so we use presets for naming and other dev features
    presets:
      name_prefix: "[dev ${workspace.current_user.short_name}] "
      tags:
        dev: ${workspace.current_user.short_name}
    
    default: true
    workspace:
      host: https://dbc-6ee8b0d3-4446.cloud.databricks.com
    variables:
      catalog: iot_streaming_dev
      schema_prefix: dev
      node_type: m5d.large  # 2 vCPU, 8GB RAM - SINGLE NODE, COST OPTIMIZED
      autotermination_minutes: 10
    
    # Development-specific resource overrides
    resources:
      pipelines:
        iot_streaming_pipeline:
          # Explicitly set development: false so cluster auto-terminates after runs
          development: false
      
      jobs:
        iot_ingestion_job:
          name: "[DEV] IoT Streaming Ingestion"
          schedule:
            quartz_cron_expression: "0 0 * * * ?"  # Hourly in dev
            timezone_id: "UTC"
        
        dbt_transformation_job:
          name: "[DEV] dbt Transformations"
          schedule:
            quartz_cron_expression: "0 30 * * * ?"  # Hourly at :30 in dev
            timezone_id: "UTC"

  # Staging environment
  staging:
    # Using presets instead of mode: development for cluster auto-termination control
    presets:
      name_prefix: "[staging ${workspace.current_user.short_name}] "
      tags:
        staging: ${workspace.current_user.short_name}
    
    workspace:
      host: https://dbc-6ee8b0d3-4446.cloud.databricks.com
    variables:
      catalog: iot_streaming_staging
      schema_prefix: staging
      node_type: m5d.large  # Same cost-optimized config for staging
      autotermination_minutes: 15
    
    resources:
      pipelines:
        iot_streaming_pipeline:
          development: false  # Enable auto-termination
      
      jobs:
        iot_ingestion_job:
          name: "[STAGING] IoT Streaming Ingestion"
          schedule:
            quartz_cron_expression: "0 */30 * * * ?"  # Every 30 min
            timezone_id: "UTC"
        
        dbt_transformation_job:
          name: "[STAGING] dbt Transformations"
          schedule:
            quartz_cron_expression: "0 15,45 * * * ?"  # Every 30 min at :15/:45
            timezone_id: "UTC"

  # Production environment
  prod:
    mode: production
    workspace:
      host: https://dbc-6ee8b0d3-4446.cloud.databricks.com
    variables:
      catalog: iot_streaming_prod
      schema_prefix: prod
      node_type: m5d.large  # Same cost-optimized config for prod
      autotermination_minutes: 20
    
    # Run as service principal in production
    run_as:
      service_principal_name: iot-pipeline-sp
    
    resources:
      jobs:
        iot_ingestion_job:
          name: "[PROD] IoT Streaming Ingestion"
          schedule:
            quartz_cron_expression: "0 */15 * * * ?"  # Every 15 min
            timezone_id: "UTC"
          
          # Production alerting
          email_notifications:
            on_failure:
              - fahad.nasim@example.com
        
        dbt_transformation_job:
          name: "[PROD] dbt Transformations"
          schedule:
            quartz_cron_expression: "0 5,20,35,50 * * * ?"  # Every 15 min offset
            timezone_id: "UTC"
          
          email_notifications:
            on_failure:
              - fahad.nasim@example.com
